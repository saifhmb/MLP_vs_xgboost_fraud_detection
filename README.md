# MLP_vs_xgboost_fraud_detection

## Introduction
  - Fraud detection is an important aspect of payments to maintain platform integrity and ensure customer trust.
  -  It is used in many industries including:
      - Banking
      - E-commerce
      - Insurance
      - Healthcare
  -  Federal Trade Commission found that consumers lost > $10 billion in 2023 due to fraud.
  -  Challenges:
      -  Some of the challenges associated with fraud detection include volume of transactions e.g millions of transactions occur on a daily basis within a banking platform.
      -  There are numerous attributes within a payment dataset from any given bank transaction.
      -  The high dimensional dataset gives rise to complex non-linear effects and feature interactions.
  - These are challenges that can be addressed using machine learning which are best suited for intrinsically hard and complex problems. The question is whether deep learning or gradient boosting would yield          better accuracy. 

## Data
  - The payments data was synthetically generated by J.P Morgan AI Research.
  - Over 1 million transactions with 12 features. Imbalanced dataset due to a much greater number of normal transactions compared to fraudulent ones.
    
    <img width="816" height="325" alt="image" src="https://github.com/user-attachments/assets/d1e37e2a-a057-4551-89ab-6ed0b13d20f6" />

    <img width="1785" height="277" alt="image" src="https://github.com/user-attachments/assets/f70c0a2a-0ab3-42a6-a10a-90e2b6b8cbfd" />

    
    <img width="589" height="455" alt="image" src="https://github.com/user-attachments/assets/50febcf5-1823-4e79-87c8-a078fe91e152" />

    <img width="1780" height="231" alt="image" src="https://github.com/user-attachments/assets/57b6bfd3-3c1b-4d00-8902-a38e1ff92838" />




## Methodology
  - Feature Engineering:
      - Time_step: transformed the time of transaction to **month**, **day**, time of day i.e **AM or PM** and **hour**.
      -  One-hot encoding and embeddings of selected categorical features:
          -    Sender_Account: Account number of the sender
          -    Sender_Country: Country of the Sender_Account
          -    Bene_Account: Account number of the recipient
          -    Bene_Country: Country of the Bene_Account
          -    Transaction_Type: Type of transaction
          -    Month: Month of transaction
          -    Weekday: Day of transaction
          -    Hour: Hour of transaction
          -    AMorPM: AM or PM
      -   Feature scaling of numerical columns(XGBoost):
          -   USD_amount: Transaction amount in USD
    
  - Performance Evaluation:
      - Label is the target variable
          - 0: Non-fraudluent
          - 1: fraudulent
      - Accuracy:
          - Accuracy = (TP + TN) / (TP + TN + FP + FN)
            
  - Machine Learning Models:
      - XGBoost
      - Multilayer Perceptron(MLP)
   
  -  Training/Testing and Validation:
      -   Imported RandomUnderSampler to complete model training using equal number of label classes
      -   XGBoost Validation: cv = 5
      -   MLP Train/test split: 85/15
      -   Hyperparameters:
            - XGBoost: Number of trees = 5000, learning rate = 0.3
            - MLP:
              <img width="962" height="532" alt="image" src="https://github.com/user-attachments/assets/68907522-8248-4640-b921-9d6c9e9814e1" />

      


## Results
  - Prediction Results:

      | Model    | Accuracy |
      |----------|----------|
      | XGBoost  | 0.61     |
      | MLP      | 0.39     |

## Conclusion
  - XGBoost models have better prediction performance for payment fraud detection than MLP models.
  - It requires less compute (CPU and High-RAM) to run XGBoost models. GPUs are needed run MLP models.


